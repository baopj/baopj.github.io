---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
About Me
======
I am **Peijun Bao (包培钧)**, currently a PhD student at [RoseLab@NTU](https://www.ntu.edu.sg/rose/about-us/our-people#Content_C001_Col00) supervised by [Prof. Alex Kot](https://personal.ntu.edu.sg/eackot/) (SAEng/IEEE Life Fellow) and [Prof. Er Meng Hwa](https://www.ntu.edu.sg/research/faculty-directory/detail/rp02304) (SAEng/IEEE Life Fellow). Additionally, I collaborate closely with [Prof. Yong Xia (NPU) ](https://scholar.google.com/citations?user=Usw1jeMAAAAJ&hl=en), [Prof. Zheng Qian (ZJU)](https://person.zju.edu.cn/zq),  [Prof. Yadong Mu (PKU)](http://www.muyadong.com/), and [Dr. Yang Wenhan (Pengcheng Lab)](https://flyywh.github.io/).

My research interests lie in the fields of computer vision and machine learning. Specifically, I am focused on the multimodal understanding of video and language. My goal is to enable machines to accurately understand the video content while keeping the manual annotation process efficient.

News
======
- [2024.08] Our ECCV paper is selected as an oral presentation! 
- [2024.07] 1 paper is accepted by ECCV 2024!
- [2023.12] 2 papers are accepted by AAAI 2024!
- [2022.12] 1 paper is accepted by AAAI 2023!
- [2022.01] 1 paper is accepted by ICMR 2022!
- [2021.01] 1 paper is accepted by AAAI 2021!
<br />
<br />

Publications 
======
Peijun Bao, Zihao Shao, Wenhan Yang, Boon Poh Ng, Alex Kot,
<br />
**E3M: Zero-Shot Spatio-Temporal Video Grounding with Expectation-Maximization Multimodal Modulation,** 
<br />
European Conference on Computer Vision (ECCV), 2024 (oral, top 2.4%) [[pdf]](https://baopj.github.io/files/ECCV24_E3M_ZeroSTVG.pdf), [[bib]](https://baopj.github.io/files/bib/E3M.txt), [[code]](https://github.com/baopj/E3M)



Peijun Bao, Zihao Shao, Wenhan Yang, Boon Poh Ng, Meng Hwa Er, Alex Kot,
<br />
**Omnipotent Distillation with LLMs for Weakly-Supervised Natural Language Video Localization: When Divergence Meets Consistency,**
<br />
Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI), 2024  [[pdf]](https://baopj.github.io/files/OmniD_AAAI2024.pdf), [[bib]](https://baopj.github.io/files/bib/OmniD.txt)


Peijun Bao, Yong Xia, Wenhan Yang, Boon Poh Ng, Meng Hwa Er, Alex Kot, 
<br />
**Local-Global Multi-Modal Distillation for Weakly-Supervised Temporal Video Grounding,** 
<br />
Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI), 2024 [[pdf]](https://baopj.github.io/files/MMDist_AAAI2024.pdf), [[bib]](https://baopj.github.io/files/bib/OmniD.txt)


Peijun Bao, Wenhan Yang, Boon Poh Ng, Meng Hwa Er, Alex Kot,
<br />
**Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization,** 
<br />
Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI), 2023 (oral) [[pdf]](https://ojs.aaai.org/index.php/AAAI/article/view/25093), [[bib]](https://baopj.github.io/files/bib/UnsupAVE.txt)


Peijun Bao, Qian Zheng, Yadong Mu,
<br />
**Dense Events Grounding in Video,** 
<br />
Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI), 2021 (oral) [[pdf]](https://baopj.github.io/files/PeijunBao_AAAI21_DenseEventsGrounding.pdf), [[bib]](https://baopj.github.io/files/bib/DepNet.txt),
[[code]](https://github.com/baopj/DenseEventsGrounding)
<br />
<small> Note: we propose a popular new task i.e. Video Paragraph Grounding. 
<br />
A list of works such as
[[CVPR24]](https://arxiv.org/pdf/2403.11463), 
[[CVPR23]](https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_Hierarchical_Semantic_Correspondence_Networks_for_Video_Paragraph_Grounding_CVPR_2023_paper.pdf), 
[[CVPR22]](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Semi-Supervised_Video_Paragraph_Grounding_With_Contrastive_Encoder_CVPR_2022_paper.pdf), 
[[AAAI24]](https://ojs.aaai.org/index.php/AAAI/article/download/27959/27938), 
[[ACM MM24]](https://openreview.net/pdf?id=DkiAOcGQHy),
[[CVIU24]](https://arxiv.org/pdf/2109.11265), 
and 
[[EMNLP22]](https://aclanthology.org/2022.emnlp-main.639.pdf) 
follow our task. </small>

Peijun Bao, Yadong Mu,
<br />
**Learning Sample Importance for Cross-Scenario Video Temporal Grounding,** 
<br />
The 12th International Conference on Multimedia Retrieval (ICMR), 2022 (oral) [[pdf]](https://arxiv.org/pdf/2201.02848.pdf), , [[bib]](https://baopj.github.io/files/bib/LSI.txt)


Chenchen Liu, Yongzhi Li, Kangqi Ma, Duo Zhang, Peijun Bao, Yadong Mu,
<br />
**Learning 3-D Human Pose Estimation from Catadioptric Videos,** 
<br />
The 30th International Joint Conference on Artificial Intelligence (IJCAI), 2021 [[pdf]](https://www.ijcai.org/proceedings/2021/0118.pdf)