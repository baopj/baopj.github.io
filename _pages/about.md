---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About Me
======
I am **Peijun Bao (包培钧)**, currently a PhD student at [RoseLab@NTU](https://www.ntu.edu.sg/rose/about-us/our-people#Content_C001_Col00) supervised by [Prof. Alex Kot](https://personal.ntu.edu.sg/eackot/) (SAEng/IEEE Fellow) and [Prof. Er Meng Hwa](https://www.ntu.edu.sg/research/faculty-directory/detail/rp02304) (SAEng/IEEE Fellow).

Additionally, I collaborate closely with [Prof. Yadong Mu (PKU)](http://www.muyadong.com/), [Prof. Zheng Qian (ZJU)](https://person.zju.edu.cn/zq), [Prof. Yong Xia (NPU) ](https://scholar.google.com/citations?user=Usw1jeMAAAAJ&hl=en), and [Dr. Yang Wenhan (Pengcheng Lab)](https://flyywh.github.io/).

My research interests lie in joint understanding of video and language.

News
======
- [2023.12] Two paper on video grounding is accepted by AAAI 2024.
- [2022.12] One paper on video localization is accepted by AAAI 2023.
- [2022.01] One paper on video grounding is accepted by ICMR 2022.
- [2021.01] One paper on video grounding is accepted by AAAI 2021.
<br />
<br />

Publications 
======
Omnipotent Distillation with LLMs for Weakly-Supervised Natural Language Video Localization: When Divergence Meets Consistency,<br />
**Peijun Bao**, Zihao Shao, Wenhan Yang, Boon Poh Ng, Meng Hwa Er, Alex Kot,<br />
*AAAI 2024* [[pdf]](https://baopj.github.io/files/OmniD_AAAI2024.pdf) 

Local-Global Multi-Modal Distillation for Weakly-Supervised Temporal Video Grounding, <br />
**Peijun Bao**, Yong Xia, Wenhan Yang, Boon Poh Ng, Meng Hwa Er, Alex Kot, <br />
*AAAI 2024* [[pdf]](https://baopj.github.io/files/MMDist_AAAI2024.pdf)

Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization, <br />
**Peijun Bao**, Wenhan Yang, Boon Poh Ng, Meng Hwa Er, Alex Kot,<br />
*AAAI 2023 (oral)* [[pdf]](https://ojs.aaai.org/index.php/AAAI/article/view/25093)

Dense Events Grounding in Video, <br />
**Peijun Bao**, Qian Zheng, Yadong Mu,<br />
*AAAI 2021 (oral)* [[pdf]](https://baopj.github.io/files/PeijunBao_AAAI21_DenseEventsGrounding.pdf) [[code]](https://github.com/baopj/DenseEventsGrounding)<br />
<small> Note: we propose a new task i.e. video paragraph grounding, and  [[CVPR23]](https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_Hierarchical_Semantic_Correspondence_Networks_for_Video_Paragraph_Grounding_CVPR_2023_paper.pdf), [[CVPR22]](https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Semi-Supervised_Video_Paragraph_Grounding_With_Contrastive_Encoder_CVPR_2022_paper.pdf), and [[EMNLP22]](https://aclanthology.org/2022.emnlp-main.639.pdf) follow our task. </small>

Learning Sample Importance for Cross-Scenario Video Temporal Grounding, <br />
**Peijun Bao**, Yadong Mu,<br />
*ICMR 2022 (oral)* [[pdf]](https://arxiv.org/pdf/2201.02848.pdf)

Learning 3-D Human Pose Estimation from Catadioptric Videos, <br />
Chenchen Liu, Yongzhi Li, Kangqi Ma, Duo Zhang, **Peijun Bao**, Yadong Mu,<br />
*IJCAI 2021* [[pdf]](https://www.ijcai.org/proceedings/2021/0118.pdf)
